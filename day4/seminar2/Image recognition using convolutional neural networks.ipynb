{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar 6\n",
    "# Image recognition using convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.333)\n",
    "s = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph model\n",
    "\n",
    "Keras allows to build networks of any kind, not just squeantially connected list of layers (a.k.a feed-forward).\n",
    "In order to do this, we need to define network graph first and then create a model:\n",
    "\n",
    "```python\n",
    "\n",
    "input1 = Input(shape=(...))\n",
    "\n",
    "layer = SuperLayer(params)(input1)\n",
    "...\n",
    "\n",
    "network = Model([input1], [output1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an X-shaped network as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_x_net():\n",
    "    ### Input layers serve as starting points in networks. \n",
    "    input1 = Input(shape=(100, ), name='Input_1')\n",
    "    dense1 = Dense(units=100, name='Dense_layer_1')(input1)\n",
    "    \n",
    "    input2 = Input(shape=(100, ), name='Input_2')\n",
    "    dense2 = Dense(units=100, name='Dense_layer_2')(input2)\n",
    "    \n",
    "    shared = Concatenate(name='Shared_features')([dense1, dense2])\n",
    "    \n",
    "    dense3 = Dense(units=100, name='Dense_layer_3')(shared)\n",
    "    concat1 = Concatenate(name='Concatenate_1')([dense1, dense3])\n",
    "    output1 = Dense(units=100, name='Output_1')(concat1)\n",
    "    \n",
    "    dense4 = Dense(units=100, name='Dense_layer_4')(shared)\n",
    "    concat2 = Concatenate(name='Concatenate_2')([dense2, dense4])\n",
    "    output2 = Dense(units=100, name='Output_2')(concat2)\n",
    "    \n",
    "    ### model just needs to know which nodes are inputs\n",
    "    ### and which are outputs\n",
    "    return Model([input1, input2], [output1, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_shaped_net = make_x_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(x_shaped_net, show_layer_names=True, show_shapes=False).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this seminar we work with CIFAR-10 dataset.\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fetch_cifar import fetch_cifar_dataset\n",
    "X_train, y_train, X_test, y_test, class_names = fetch_cifar_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = 10\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.set_title('%s' % (class_names[np.where(y_train[k] > 0.0)[0][0]]))\n",
    "        im = ax.imshow(X_train[k])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's convolve!\n",
    "\n",
    "#### Neuro-biologist studying visual perception (Hubel and Wiesel experiments)\n",
    "\n",
    "![Image](https://goodpsychology.files.wordpress.com/2013/03/hubel-experiment.jpg)\n",
    "\n",
    "#### Data scientists studying visual perception (no animal cruelty involved)\n",
    "\n",
    "![Image](http://deeplearning.net/tutorial/_images/mylenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### importing keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dense, GlobalMaxPooling2D\n",
    "from keras.activations import relu\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_cifar_cnn():\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    net = inputs\n",
    "    \n",
    "    leaky_relu = lambda x: relu(x, alpha=5.0e-2)\n",
    "    regularization_coef = 1.0e-4\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 4,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 16,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = GlobalMaxPooling2D()(net)\n",
    "    \n",
    "    net = Dense(10, activation='softmax', kernel_regularizer = l2(regularization_coef))(net)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = make_cifar_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(cnn, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling and training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### since the problem is a classification one;\n",
    "### cross-entropy is the most common choice.  \n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "### pretty usual choice of optimizer\n",
    "from keras.optimizers import adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### compile\n",
    "cnn.compile(optimizer=adamax(lr=5.0e-3), loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### fit\n",
    "cnn.fit(X_train, y_train, batch_size=32, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = cnn.predict(X_test)\n",
    "print('Accuracy:', np.mean( np.argmax(y_predicted, axis=1) ==  np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-vs-rest ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fprs, tprs = [None] * 10, [None] * 10\n",
    "aucs = [None] * 10\n",
    "\n",
    "for i in range(10):\n",
    "    fprs[i], tprs[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "    aucs[i] = auc(fprs[i], tprs[i], reorder=True)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "\n",
    "plt.title('One-vs-rest ROC curves', fontsize=16)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(fprs[i], tprs[i], label='%s (AUC %.2lf)' % (class_names[i], aucs[i]))\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_classes = np.argmax(y_predicted, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "c_matrix = confusion_matrix(y_true_classes, y_predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Diagonal excluded\n",
    "c_matrix[np.arange(10), np.arange(10)] = 0.0\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Confusion matrix (diagonal excluded)', fontsize=16)\n",
    "plt.imshow(c_matrix)\n",
    "plt.xticks(np.arange(10), class_names, rotation=45, fontsize=14)\n",
    "plt.yticks(np.arange(10), class_names, fontsize=14)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = 7\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_test.shape[0])\n",
    "        \n",
    "        y_pred = y_predicted[k]\n",
    "        predicted_class = np.argmax(y_pred)\n",
    "        real_class = np.argmax(y_test[k])\n",
    "        score = y_pred[predicted_class]\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        if real_class == predicted_class:\n",
    "            ax.set_title('%s\\nscore: %.3lf' % (class_names[real_class], score))\n",
    "        else:\n",
    "            ax.set_title('real: %s;\\npredicted: %s\\nwith score: %.3lf' % (\n",
    "                class_names[real_class], class_names[predicted_class], score\n",
    "            ))\n",
    "        im = ax.imshow(X_test[k])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can you do?\n",
    "\n",
    "Here is a several tips on how you can improve the base solution:\n",
    "- add more layers;\n",
    "- add BatchNormalization;\n",
    "- play with activations;\n",
    "- try adjusting regularization;\n",
    "- increase number of filters;\n",
    "- make it fully convolutional (get rid of GlobalMaxPooling by convolving/maxpooling up to 1x1 image, you can use Reshape or Flatten layers to get rid of spatial dimensions);\n",
    "- experiment with the architecture:\n",
    "    - try use conv-conv-pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cheat sheet\n",
    "\n",
    "The standard convolutional networks are built from several types of layers:\n",
    "- [`Convolution`](https://keras.io/layers/convolutional/), ... - performs ... convolution:\n",
    "    - filters: number of filters to use, usually, the number of layers is two timex number of layers in the previous conv. layer; \n",
    "    - kernel_size: size of the convolutional operator, conventional choice is (3, 3);\n",
    "    - padding: padding='same' extends sample with zeros so that sample after convolution has the same width and height, padding='valid' performs convolution only in points where kernel and the sample fully overlap.  \n",
    "    - activation: conventional choice is ReLU or a leaky ReLU.\n",
    "\n",
    "- [`MaxPooling`](https://keras.io/layers/convolutional/) - pools maximal values from pooling area, average pooling is an alternative.\n",
    "\n",
    "- [`GlobalMaxPooling`](https://keras.io/layers/convolutional/) - similar to max pool, but pools from the whole sample/image.\n",
    "\n",
    "- [`Dense`](https://keras.io/layers/core/) - usually is at the end of the network.\n",
    "\n",
    "#### Conv\n",
    "![Image](http://deeplearning.net/tutorial/_images/cnn_explained.png)\n",
    "\n",
    "#### MaxPool\n",
    "\n",
    "![Image](http://cs231n.github.io/assets/cnn/maxpool.jpeg)\n",
    "\n",
    "#### Conv network\n",
    "\n",
    "![Image](http://deeplearning.net/tutorial/_images/mylenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### importing keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dense, GlobalMaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.activations import relu, elu, softplus, tanh, sigmoid\n",
    "from keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_super_cnn():\n",
    "    ###\n",
    "    leaky_relu = lambda x: relu(x, alpha=5.0e-2)\n",
    "    regularization_coef = 1.0e-6\n",
    "\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    net = inputs\n",
    "    \n",
    "    ### your network here\n",
    "    \n",
    "    ### previous solution     ###\n",
    "    ### feel free to throw it ###\n",
    "    net = Convolution2D(\n",
    "        filters = 4,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 16,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = GlobalMaxPooling2D()(net)\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    net = Dense(\n",
    "        10, activation='softmax',\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_cnn = make_super_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(super_cnn, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### since the problem is a classification one;\n",
    "### cross-entropy is the most common choice.  \n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "### Feel free to play with optimizers\n",
    "### don't forget to adjust learning rate\n",
    "from keras.optimizers import adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### compile\n",
    "super_cnn.compile(optimizer=adamax(lr=5.0e-3), loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_cnn.fit(X_train, y_train, batch_size=32, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = cnn.predict(X_test)\n",
    "print('Accuracy:', np.mean( np.argmax(y_predicted, axis=1) ==  np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fprs, tprs = [None] * 10, [None] * 10\n",
    "aucs = [None] * 10\n",
    "\n",
    "for i in range(10):\n",
    "    fprs[i], tprs[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "    aucs[i] = auc(fprs[i], tprs[i], reorder=True)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "\n",
    "plt.title('One-vs-rest ROC curves')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(fprs[i], tprs[i], label='%s (AUC %.2lf)' % (class_names[i], aucs[i]))\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Diagonal excluded\n",
    "c_matrix[np.arange(10), np.arange(10)] = 0.0\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Confusion matrix (diagonal excluded)', fontsize=16)\n",
    "plt.imshow(c_matrix)\n",
    "plt.xticks(np.arange(10), class_names, rotation=45, fontsize=14)\n",
    "plt.yticks(np.arange(10), class_names, fontsize=14)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = 7\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_test.shape[0])\n",
    "        \n",
    "        y_pred = y_predicted[k]\n",
    "        predicted_class = np.argmax(y_pred)\n",
    "        real_class = np.argmax(y_test[k])\n",
    "        score = y_pred[predicted_class]\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        if real_class == predicted_class:\n",
    "            ax.set_title('%s\\nscore: %.3lf' % (class_names[real_class], score))\n",
    "        else:\n",
    "            ax.set_title('real: %s;\\npredicted: %s\\nwith score: %.3lf' % (\n",
    "                class_names[real_class], class_names[predicted_class], score\n",
    "            ))\n",
    "        im = ax.imshow(X_test[k])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Deep Jets\n",
    "\n",
    "**WARNING: HARDCORE physics! Details are in the next lecture by Noel Dawe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import h5py\n",
    "\n",
    "DATA_ROOT = '../../../data/deepjets'\n",
    "SIGNAL_PATH = osp.join(DATA_ROOT, 'w_100000_j1p0_sj0p30_delphes_jets_images.h5')\n",
    "BACKGROUND_PATH = osp.join(DATA_ROOT, 'qcd_100000_j1p0_sj0p30_delphes_jets_images.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images(filename):\n",
    "    hfile = h5py.File(filename, 'r')\n",
    "    images = hfile['images'].value.astype('float32')\n",
    "\n",
    "    mass = hfile['auxvars']['mass']\n",
    "    pt = hfile['auxvars']['pt']\n",
    "    hfile.close()\n",
    "\n",
    "    # select images in window 50 < mass < 150 GeV and 200 < pt < 300 GeV\n",
    "    #images = images[(mass > 50) & (mass < 150) & (pt > 200) & (pt < 300)]\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_signal = get_images(SIGNAL_PATH)\n",
    "X_background = get_images(BACKGROUND_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_background.shape)\n",
    "print(X_signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack([X_signal, X_background]).reshape(-1, 25, 25, 1)\n",
    "y = np.hstack([np.ones(X_signal.shape[0], dtype='float32'), np.zeros(X_background.shape[0], dtype='float32')])\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(\n",
    "    [np.mean(X_train[y_train[:, 1] == 1], axis=(1, 2, 3)), np.mean(X_train[y_train[:, 1] == 0], axis=(1, 2, 3))],\n",
    "    bins=100, histtype='step', log=True, label=['W', 'QCD']\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = 8\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 3 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.set_title('%s' % ( \"W\" if y_train[k, 1] == 1 else \"QCD\"))\n",
    "        im = ax.imshow(X_train[k, :, :, 0].T, origin='low', cmap=plt.cm.plasma)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### importing keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dense, GlobalMaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.activations import relu, elu, softplus, tanh, sigmoid\n",
    "from keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_jet_cnn():\n",
    "    ###\n",
    "    leaky_relu = lambda x: relu(x, alpha=5.0e-2)\n",
    "    regularization_coef = 1.0e-6\n",
    "    \n",
    "    ### Note that jets has 1 input channel and different size!\n",
    "    inputs = Input(shape=(25, 25, 1))\n",
    "    normalization = BatchNormalization()(inputs)\n",
    "    \n",
    "    net = normalization\n",
    "    \n",
    "    ### your network here\n",
    "    \n",
    "    ### previous solution     ###\n",
    "    ### feel free to throw it ###\n",
    "    net = Convolution2D(\n",
    "        filters = 32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_initializer='he_uniform',\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_initializer='he_uniform',\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 128,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_initializer='he_uniform',\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 256,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_initializer='he_uniform',\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((3, 3))(net)\n",
    "    \n",
    "    net = Flatten()(net)\n",
    "    \n",
    "    ### also, 2 classes instead of 10\n",
    "    net = Dense(2, activation='softmax')(net)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jet_net = make_jet_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(jet_net, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jet_net.compile(optimizer=adamax(lr=1.0e-3), loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jet_net.fit(X_train, y_train, batch_size=32, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = jet_net.predict(X_test)\n",
    "print('Accuracy:', np.mean( np.argmax(y_predicted, axis=1) ==  np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test[:, 1], y_predicted[:, 1])\n",
    "auc_score = auc(fpr, tpr, reorder=True)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "\n",
    "plt.title('One-vs-rest ROC curves')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.plot(fpr, tpr, label='W vs QCD (AUC %.3lf)' % (auc_score))\n",
    "\n",
    "plt.legend(fontsize=14, loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['QCD', 'W']\n",
    "\n",
    "cols = 7\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_test.shape[0])\n",
    "        \n",
    "        y_pred = y_predicted[k]\n",
    "        predicted_class = np.argmax(y_pred)\n",
    "        real_class = np.argmax(y_test[k])\n",
    "        score = y_pred[predicted_class]\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        if real_class == predicted_class:\n",
    "            ax.set_title('%s\\nscore: %.3lf' % (class_names[real_class], score))\n",
    "        else:\n",
    "            ax.set_title('real: %s;\\npredicted: %s\\nwith score: %.3lf' % (\n",
    "                class_names[real_class], class_names[predicted_class], score\n",
    "            ))\n",
    "        im = ax.imshow(X_train[k, :, :, 0].T, origin='low', cmap=plt.cm.plasma)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
